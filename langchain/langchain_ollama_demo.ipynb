{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebafd90-e079-4098-bf18-f9732aac41ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='北京天气怎么样', additional_kwargs={}, response_metadata={}, id='76a0a1bb-f3d9-4d25-acfe-1c7c75f73990'),\n",
       "  AIMessage(content='Okay, the user is asking about the weather in Beijing. Let me check the tools provided. There\\'s a function called get_weather that takes a city as a parameter. The city here is Beijing. So I need to call that function with city set to \"北京\". Let me make sure the parameters are correct. The function expects a city string, and the user mentioned Beijing, which is a city in China. I should structure the tool call correctly. The tool name is get_weather, arguments should be {\"city\": \"北京\"}. Let me format the JSON as specified. No other tools are available, so this is the only one to call.\\n</think>\\n\\n', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2026-01-17T14:46:44.1158413Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2264033800, 'load_duration': 61442100, 'prompt_eval_count': 140, 'prompt_eval_duration': 90404900, 'eval_count': 153, 'eval_duration': 2042288500, 'logprobs': None, 'model_name': 'qwen3:4b', 'model_provider': 'ollama'}, id='lc_run--019bcc6c-33b5-73c2-bcda-f2fcb16f4ace-0', tool_calls=[{'name': 'get_weather', 'args': {'city': '北京'}, 'id': '140a6d9e-4276-4e0a-96ce-1c9cea6a802c', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 140, 'output_tokens': 153, 'total_tokens': 293}),\n",
       "  ToolMessage(content='北京是个大晴天，适合出去游玩!', name='get_weather', id='c88cdbcf-08b9-4ed8-8a01-ff1519fb95d2', tool_call_id='140a6d9e-4276-4e0a-96ce-1c9cea6a802c'),\n",
       "  AIMessage(content='Okay, let me process this step by step. The user asked about the weather in Beijing. I called the get_weather function with the city set to \"北京\". The response from the tool says \"北京是个大晴天，适合出去游玩!\" which translates to \"Beijing is a sunny day, good for going out!\"\\n\\nNow I need to present this information in a friendly and helpful way. The user probably wants a concise answer without technical jargon. I should translate the Chinese response into English for clarity, but wait, the user\\'s original question was in Chinese (\"北京天气怎么样\"), so maybe they expect the answer in Chinese? Wait, the user\\'s message is in Chinese, but the tool response is in Chinese. Let me check.\\n\\nThe user wrote \"北京天气怎么样\" which means \"How\\'s the weather in Beijing?\" So the response should be in Chinese. The tool response is \"北京是个大晴天，适合出去游玩!\" which is Chinese. So I should respond in Chinese.\\n\\nWait, but the previous tool response is in Chinese. So the assistant should just relay that message. Let me confirm. The tool response is in Chinese, so the answer to the user should be the same. So the response would be: 北京是个大晴天，适合出去游玩!\\n\\nBut maybe the user expects a natural translation. Wait, the example given in the tool response is in Chinese. Let\\'s see. The user\\'s question is in Chinese, so the answer should be in Chinese. The tool response is already in Chinese, so the assistant can just output that.\\n\\nWait, the problem says: the user\\'s message is in Chinese, so the assistant should respond in Chinese. The tool response is in Chinese, so the answer is straightforward. So the final answer is the tool response.\\n\\nBut let me make sure. The tool response says \"北京是个大晴天，适合出去游玩!\" which is correct. So the assistant should just return that message to the user.\\n\\nYes, so the response is: 北京是个大晴天，适合出去游玩!\\n</think>\\n\\n北京是个大晴天，适合出去游玩!', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2026-01-17T14:46:50.3473894Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6219328600, 'load_duration': 62950700, 'prompt_eval_count': 314, 'prompt_eval_duration': 71997100, 'eval_count': 433, 'eval_duration': 5897573200, 'logprobs': None, 'model_name': 'qwen3:4b', 'model_provider': 'ollama'}, id='lc_run--019bcc6c-3c9a-7193-8be0-70049a543b46-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 314, 'output_tokens': 433, 'total_tokens': 747})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.langchain.com/oss/python/langchain/quickstart\n",
    "from langchain.agents import create_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"{city}是个大晴天，适合出去游玩!\"\n",
    "\n",
    "model = ChatOllama(model=\"qwen3:4b\", reasoning=False)\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"北京天气怎么样\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a1f83-8799-4b70-8f94-5388d19d581e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
